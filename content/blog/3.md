---
title: "Amazon S3のファイルをRDSにロードして使う"
published: true
date: 2025-11-04
tags:
  - permanent
---

## 調査

- `LOAD DATE FROM S3 FILE 's3://[bucket]/path/to/file/path.csv'`が使えそう
  - RDS → S3にアクセスするロールが必要
  - RDSクラスタとロールを紐づける設定も必要っぽく、つまづいた
- `AWS Database Migration Service(DMS)`でデータ移行
  - 使ったことのないサービスだったため、時間の制約を考慮して断念した
    （もっと時間があれば、しっかり検証した上で使っても良かったかも）

## 検証(LOAD DATE FROM S3)

- 1万件、10万件、50万件のデータで検証
  - 1万件: 約0.3秒
  - 10万件: 約1.8秒
  - 50万件: 約8秒
- テーブル定義は int / varchar(191) / tinyint の計6カラム
- uniqueキーが2つ、外部キー（indexあり）が1つ

---

## 実際にやったこと

1. IAMロールの作成
   - S3バケットへの読み取り権限（`s3:GetObject`）を持つIAMロールを作成
   - RDSインスタンスが引き受けられるように、信頼ポリシーで `rds.amazonaws.com` サービスを許可する必要がある

2. RDSインスタンスへのIAMロールのアタッチ
   - RDSコンソールまたはAWS CLIにて、作成したIAMロールを対象のRDSインスタンスにアタッチする
   - 「IAM ロールを DB インスタンスにアタッチする」または「S3 からデータをロードする権限を付与する」といった設定で行う

3. クエリの実行

```sql
LOAD DATA FROM S3 FILE 's3://[bucket-name]/[path]/[file_name].csv'
INTO TABLE [target_rds_table_name]
FIELDS TERMINATED BY ','  -- CSVファイルの場合、カンマ区切り
ENCLOSED BY '"'           -- ダブルクォーテーションで囲まれている場合
LINES TERMINATED BY '\n'  -- 行の終端は改行
IGNORE 1 LINES            -- ヘッダー行をスキップする場合
(col1, col2, col3, ...);  -- テーブルのカラム名とCSVの列の順序が一致している場合(CSVにないカラムは指定しない)
```

### 参考

[Amazon S3 バケットのテキストファイルから Amazon Aurora MySQL DB クラスターへのデータのロード](https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Integrating.LoadFromS3.html)
